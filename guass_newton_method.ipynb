{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python369jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.6.9 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### Solve Nonlinear Least-Squares Problem with the Gauss-Newton Methods.  \n",
    "#### What is linear/nonlinear?  \n",
    "* Linear: A polynomial of degree 1.  \n",
    "* Nonlinear: A function can't be expressed by the A polynomial of degree 1.   \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### What is Least-Squares Problem?  \n",
    "f(x) is the objective function, x is the parameter vector.  \n",
    "The least-squares problem tries to find optimal parameters to minimize the overall cost. \n",
    "$$ \n",
    "cost = \\sum_{i=0}^{n}f(x)^2 \\quad\n",
    "$$\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### What is Gauss-Newton Methods?  \n",
    "The gauss–newton methods is used to solve nonlinear least-squares problems.  \n",
    "Unlike Newton's method, gauss-newton methods are not necessary to calculate second derivatves,  \n",
    "which may difficult to compute in some cases.  \n",
    "Gauss–newton methods update x using iterative method, the update amount is Δx. \n",
    "\n",
    "$$ \n",
    "\\Delta x = -H^{-1}g\n",
    "$$\n",
    "here: g is the gradient vector; H is the hessian matrix.\n",
    "$$ \n",
    "g = -J^Te\n",
    "$$\n",
    "$$ \n",
    "H \\approx J^TJ\n",
    "$$\n",
    "J is the jacobian matrix, e is the residual vector. \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 3d point-matching problems.  \n",
    "The objective function of 3d point-matching:  \n",
    "$$ \n",
    "f = T(x)(a) - b\n",
    "$$\n",
    "According to chain rule, the jacobian matrix of f can compute as following:  \n",
    "$$ \n",
    "J=\\frac{\\partial f}{\\partial T} \\frac{\\partial T}{\\partial x}\n",
    "$$ \n",
    "The df/dT:  \n",
    "$$\n",
    "\\frac{\\partial f}{\\partial T}=\\left|\n",
    "\\begin{matrix} \n",
    "a_1 & a_2 & a_3 & 1 & 0 & 0 & 0 & 0  & 0 & 0 & 0 & 0\\\\ \n",
    "0 & 0 & 0 & 0 & a_1 & a_2 & a_3 & 1 & 0 & 0 & 0 & 0\\\\ \n",
    "0 & 0 & 0 & 0 & 0 & 0 & 0 & 0  & a_1 & a_2 & a_3 & 1\n",
    "\\end{matrix}\n",
    "\\right|\n",
    "$$\n",
    "T is the transform function, x is the parameter vector of T. a and b are 2 different points.  \n",
    "$$ \n",
    "x=[x_1, x_2, x_3, x_4, x_5, x_6]\n",
    "$$ \n",
    "x_1, x_2, x_3 are translation parameters.  \n",
    "x_4, x_5, x_6 are rotation parameters, we use so3 parameters to represent rotation.    \n",
    "\n",
    "$$ \n",
    "T(x_1, x_2, x_3, x_4, x_5, x_6) = R(x_4, x_5, x_6)a + t(x_1, x_2, x_3)  \n",
    "$$ \n",
    "The dT/dx:  \n",
    "$$\n",
    "\\frac{\\partial T}{\\partial x}=\\left|\n",
    "\\begin{matrix} \n",
    "    0 & 0& 0& 1&  0& 0& 0& 0&  0& 0& 0& 0\\\\\n",
    "    0 & 0& 0& 0&  0& 0& 0& 1&  0& 0& 0& 0\\\\\n",
    "    0 & 0& 0& 0&  0& 0& 0& 0&  0& 0& 0& 1\\\\\n",
    "    0 & 0& 0& 0&  0& 0&-1& 0&  0& 1& 0& 0\\\\\n",
    "    0 & 0& 1& 0&  0& 0& 0& 0& -1& 0& 0& 0\\\\\n",
    "    0 &-1& 0& 0&  1& 0& 0& 0&  0& 0& 0& 0\\\\\n",
    "\\end{matrix}\n",
    "\\right|\n",
    "$$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}